
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>EEGStudyInterface</title><meta name="generator" content="MATLAB 8.4"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2016-06-07"><meta name="DC.source" content="EEGStudyInterface.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#3">helper functions, to be called inside each subclass</a></li><li><a href="#4">Exploratory Analysis primarily Unsupervised Learning, NOW the exciting part</a></li><li><a href="#5">helper plot functions</a></li><li><a href="#6">Quantitative Analysis primarily Supervised Learning, the even more exciting part</a></li></ul></div><pre class="codeinput"><span class="keyword">classdef</span> EEGStudyInterface &lt; handle
    <span class="comment">% overall flow of one study</span>
    <span class="comment">% concrete class includes specific eegdata</span>
    <span class="keyword">properties</span>
        data_windows = [] <span class="comment">% an array that saves all data windows</span>
        EEGData <span class="comment">% source data file, handles I/O</span>
        start_locs
        window_length
        feature_matrix = []
        num_windows
        window_generator = <span class="string">'EEGWindowInterface'</span>
        stride
        toString
        color_codes <span class="comment">% used to indicate the class that current window belongs to</span>
        S = []          <span class="comment">% should consider</span>
        V = []<span class="comment">% used to store result from pca</span>
        color_types
        idx
        C
        pca_coordinates
    <span class="keyword">end</span>

    <span class="keyword">methods</span>
</pre><pre class="codeinput">        <span class="keyword">function</span> import_data(obj)
            <span class="comment">%  maybe rather than subclassing, change to just function calls,</span>
            <span class="comment">% but I guess it might be a sensible thing to do when there are some many parameters to set</span>

            obj.EEGData = EEGDataMIT();
            obj.EEGData.load_set(<span class="string">'/Users/Zhe/Documents/seizure/myeegcode/test_MIT_Data/test_MIT_rejected.set'</span>);
            obj.EEGData.set_name(<span class="string">'test_MIT'</span>);
            obj.EEGData.seizure_times = [2996, 3036];


        <span class="keyword">end</span>

        <span class="keyword">function</span> set_window_params(obj, window_length, stride, window_generator)
            obj.window_length = window_length;
            obj.stride = stride;
            obj.window_generator = window_generator;
            obj.gen_data_windows()

        <span class="keyword">end</span>

        <span class="keyword">function</span> gen_data_windows(obj)

            <span class="comment">% generate window location</span>
            obj.start_locs = 0: obj.stride : (obj.EEGData.total_length - obj.window_length);
            <span class="comment">% obj.start_locs = 2800: obj.stride: 3200; % I changed this because compressive sensing is just too slow</span>
            <span class="keyword">for</span> start_loc = obj.start_locs
                curwindow = feval(obj.window_generator);
                obj.EEGData.gen_raw_window(start_loc, obj.window_length, curwindow); <span class="comment">%TODO changed backed to raw window</span>
                obj.data_windows = [obj.data_windows, curwindow];

            <span class="keyword">end</span>
            obj.num_windows = length(obj.start_locs);
            obj.gen_feature_matrix();
            obj.toString = [class(obj) <span class="string">'from 0 to '</span> num2str(obj.EEGData.total_length) <span class="string">' with '</span> num2str(obj.num_windows) <span class="string">' '</span> obj.window_generator ];
        <span class="keyword">end</span>
</pre><h2>helper functions, to be called inside each subclass<a name="3"></a></h2><pre class="codeinput">        <span class="keyword">function</span> gen_feature_matrix(obj)
            <span class="comment">% pull extracted features from each eeg window to form a matrix for fitting</span>
            <span class="comment">% ASSUME that we are using flattened column vector features</span>
            <span class="comment">% we would not use that for ,say, convolution neural network(CNN)</span>
            feature_matrix = [];
            color_codes = [];
            color_types = [];
            <span class="keyword">for</span> cur_window  = obj.data_windows
                feature_matrix = [feature_matrix, cur_window.flattened_feature];
                color_codes = [color_codes, cur_window.color_code];
                color_types = [color_types, cur_window.get_color_type()];
            <span class="keyword">end</span>
            obj.feature_matrix = feature_matrix';
            obj.color_codes = color_codes;
            obj.color_types = color_types;
        <span class="keyword">end</span>
</pre><h2>Exploratory Analysis primarily Unsupervised Learning, NOW the exciting part<a name="4"></a></h2><h2>helper plot functions<a name="5"></a></h2><pre class="codeinput">        <span class="keyword">function</span> bar_plot(obj, clusters)
            <span class="comment">% barplot test</span>
            <span class="comment">% given two vectors x, y with x indicating the class member ship and y the</span>
            <span class="comment">% submembership</span>
            <span class="comment">% draw barplots</span>

            x = clusters(:);
            y = obj.color_types(:);
            combi = [x y];
            result = [];
            count_num = @(sample_vector) sum(not(any(bsxfun(@minus, combi, sample_vector), 2)));
            <span class="keyword">for</span> cluster = sort(unique(x))'
                currow = [];
                <span class="keyword">for</span> type = sort(unique(y))'
                    sample_vector = [cluster, type];
                    currow = [currow, count_num(sample_vector)];
                <span class="keyword">end</span>
                result = [result; currow];
            <span class="keyword">end</span>
            bar(result)
            colorbar()
        <span class="keyword">end</span>

        <span class="comment">% pca</span>
        <span class="keyword">function</span> pca(obj)
            data_mat = obj.feature_matrix;
            <span class="keyword">if</span> isempty(obj.V)
                [U,S,V] = svd(data_mat);
                obj.V = V;
                obj.S = S;
            <span class="keyword">else</span>
                V = obj.V;
                S = obj.S;
            <span class="keyword">end</span>
            pca_coordinates = data_mat * V(:, 1:3);

            obj.pca_coordinates = pca_coordinates;
        <span class="keyword">end</span>

        <span class="keyword">function</span> plot_pca(obj)
            obj.pca();

            figure()
            pca_coordinates = obj.pca_coordinates;
            subplot(131)
            bar(diag(obj.S))
            title([<span class="string">'PCA'</span> obj.toString])

            subplot(132)

            scatter(pca_coordinates(:,1), pca_coordinates(:,2), 50,obj.color_codes, <span class="string">'filled'</span>)
            <span class="comment">% %TODO changed scale for fair comparison</span>
            subplot(133)
            scatter3(pca_coordinates(:, 1), pca_coordinates(:, 2), pca_coordinates(:, 3), 50, obj.color_codes, <span class="string">'filled'</span>);
            <span class="comment">% zlim([-0.4, 0.4])</span>
            colorbar()
        <span class="keyword">end</span>

        <span class="keyword">function</span> porp = k_means(obj, k)
            <span class="comment">% function for normalize a vector</span>
            <span class="comment">% porp the percentage of correct clustering</span>
            data_mat = obj.feature_matrix;
            <span class="comment">% pool = parpool;                      % Invokes workers</span>
            <span class="comment">% stream = RandStream('mlfg6331_64');  % Random number stream</span>
            <span class="comment">% options = statset('UseParallel',1,'UseSubstreams',1,...</span>
            <span class="comment">%                     'Streams',stream);</span>

            figure()
            [idx, C] = kmeans(data_mat, k,<span class="string">'MaxIter'</span>,1000,<span class="string">'Display'</span>, <span class="string">'iter'</span> ) ;
            obj.idx = idx;
            obj.C = C;
            disp(<span class="string">'finishing kmeans clustering'</span>);

            subplot(121)
            plot(C')
            title(<span class="string">'kmeans vectors'</span>)

            ss = 1:k;
            ss = arrayfun(@num2str, ss, <span class="string">'UniformOutput'</span>, false);
            legend(ss)

            subplot(122)
            obj.bar_plot(idx);
            title(<span class="string">'group disribution'</span>)



            first_window = obj.data_windows(1);
            n = 3; <span class="comment">% number of subplots per graph</span>
            <span class="keyword">for</span> i = 0:1:floor(k/n)
                figure()
                <span class="keyword">for</span> j = 1:n
                    curidx = n * i + j;
                    <span class="keyword">if</span> curidx &gt; k
                        <span class="keyword">break</span>
                    <span class="keyword">end</span>
                    subplot(1, n, j)
                    curfeature = C(curidx, :);
                    first_window.plot_his_feature(curfeature(:));
                    title(sprintf(<span class="string">'%d th compoenent'</span>,curidx))
                <span class="keyword">end</span>
            <span class="keyword">end</span>

            <span class="keyword">for</span> i = 0:1:floor(k/n)
                <span class="comment">% plot raw temporal data</span>
                <span class="comment">% figure()</span>
                <span class="keyword">for</span> j = 1:n
                    curidx = n * i + j;
                    <span class="keyword">if</span> curidx &gt; k
                        <span class="keyword">break</span>
                    <span class="keyword">end</span>
                    windowidx = find(idx == curidx);
                    first_window = obj.data_windows(windowidx);

                    first_window.plot_raw_feature();
                    title(sprintf(<span class="string">'%d th compoenent'</span>,curidx));
                <span class="keyword">end</span>
            <span class="keyword">end</span>


            obj.pca();
            pca_coordinates = obj.pca_coordinates;
            figure()
            scatter(pca_coordinates(:,1), pca_coordinates(:,2), 50,obj.idx, <span class="string">'filled'</span>)
            colorbar;
            <span class="comment">% show original temporal feature(time series) corresponding to each feature, take the mean</span>

        <span class="keyword">end</span>
</pre><h2>Quantitative Analysis primarily Supervised Learning, the even more exciting part<a name="6"></a></h2><pre class="codeinput">    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2014b</a><br></p></div><!--
##### SOURCE BEGIN #####
classdef EEGStudyInterface < handle
    % overall flow of one study
    % concrete class includes specific eegdata 
    properties
        data_windows = [] % an array that saves all data windows
        EEGData % source data file, handles I/O
        start_locs
        window_length
        feature_matrix = []
        num_windows
        window_generator = 'EEGWindowInterface'
        stride
        toString
        color_codes % used to indicate the class that current window belongs to 
        S = []          % should consider
        V = []% used to store result from pca
        color_types
        idx
        C
        pca_coordinates
    end

    methods

        function import_data(obj)
            %  maybe rather than subclassing, change to just function calls, 
            % but I guess it might be a sensible thing to do when there are some many parameters to set

            obj.EEGData = EEGDataMIT();
            obj.EEGData.load_set('/Users/Zhe/Documents/seizure/myeegcode/test_MIT_Data/test_MIT_rejected.set');
            obj.EEGData.set_name('test_MIT');
            obj.EEGData.seizure_times = [2996, 3036];


        end

        function set_window_params(obj, window_length, stride, window_generator)
            obj.window_length = window_length;
            obj.stride = stride;
            obj.window_generator = window_generator;
            obj.gen_data_windows()

        end

        function gen_data_windows(obj) 

            % generate window location
            obj.start_locs = 0: obj.stride : (obj.EEGData.total_length - obj.window_length);
            % obj.start_locs = 2800: obj.stride: 3200; % I changed this because compressive sensing is just too slow
            for start_loc = obj.start_locs
                curwindow = feval(obj.window_generator);
                obj.EEGData.gen_raw_window(start_loc, obj.window_length, curwindow); %TODO changed backed to raw window
                obj.data_windows = [obj.data_windows, curwindow];

            end
            obj.num_windows = length(obj.start_locs);
            obj.gen_feature_matrix();
            obj.toString = [class(obj) 'from 0 to ' num2str(obj.EEGData.total_length) ' with ' num2str(obj.num_windows) ' ' obj.window_generator ];
        end

        %% helper functions, to be called inside each subclass


        function gen_feature_matrix(obj)
            % pull extracted features from each eeg window to form a matrix for fitting
            % ASSUME that we are using flattened column vector features
            % we would not use that for ,say, convolution neural network(CNN)
            feature_matrix = [];
            color_codes = [];
            color_types = [];
            for cur_window  = obj.data_windows
                feature_matrix = [feature_matrix, cur_window.flattened_feature];
                color_codes = [color_codes, cur_window.color_code];
                color_types = [color_types, cur_window.get_color_type()];
            end
            obj.feature_matrix = feature_matrix';
            obj.color_codes = color_codes;
            obj.color_types = color_types;
        end

        %% Exploratory Analysis primarily Unsupervised Learning, NOW the exciting part

        %% helper plot functions

        function bar_plot(obj, clusters)
            % barplot test
            % given two vectors x, y with x indicating the class member ship and y the
            % submembership
            % draw barplots

            x = clusters(:);
            y = obj.color_types(:);
            combi = [x y];
            result = [];
            count_num = @(sample_vector) sum(not(any(bsxfun(@minus, combi, sample_vector), 2)));
            for cluster = sort(unique(x))'
                currow = [];
                for type = sort(unique(y))'
                    sample_vector = [cluster, type];
                    currow = [currow, count_num(sample_vector)];
                end
                result = [result; currow];
            end
            bar(result)
            colorbar()
        end

        % pca
        function pca(obj)
            data_mat = obj.feature_matrix;
            if isempty(obj.V)
                [U,S,V] = svd(data_mat);
                obj.V = V;
                obj.S = S;
            else
                V = obj.V;
                S = obj.S;
            end
            pca_coordinates = data_mat * V(:, 1:3);
            
            obj.pca_coordinates = pca_coordinates;
        end

        function plot_pca(obj)
            obj.pca();

            figure()
            pca_coordinates = obj.pca_coordinates;
            subplot(131)
            bar(diag(obj.S))
            title(['PCA' obj.toString])

            subplot(132)
            
            scatter(pca_coordinates(:,1), pca_coordinates(:,2), 50,obj.color_codes, 'filled')
            % %TODO changed scale for fair comparison
            subplot(133)
            scatter3(pca_coordinates(:, 1), pca_coordinates(:, 2), pca_coordinates(:, 3), 50, obj.color_codes, 'filled');
            % zlim([-0.4, 0.4])
            colorbar()
        end

        function porp = k_means(obj, k)
            % function for normalize a vector 
            % porp the percentage of correct clustering
            data_mat = obj.feature_matrix;
            % pool = parpool;                      % Invokes workers
            % stream = RandStream('mlfg6331_64');  % Random number stream
            % options = statset('UseParallel',1,'UseSubstreams',1,...
            %                     'Streams',stream);

            figure()
            [idx, C] = kmeans(data_mat, k,'MaxIter',1000,'Display', 'iter' ) ;
            obj.idx = idx;
            obj.C = C;
            disp('finishing kmeans clustering');

            subplot(121)
            plot(C')
            title('kmeans vectors')
            
            ss = 1:k;
            ss = arrayfun(@num2str, ss, 'UniformOutput', false);
            legend(ss)

            subplot(122)
            obj.bar_plot(idx);
            title('group disribution')



            first_window = obj.data_windows(1);
            n = 3; % number of subplots per graph
            for i = 0:1:floor(k/n)                
                figure()
                for j = 1:n
                    curidx = n * i + j;
                    if curidx > k
                        break
                    end
                    subplot(1, n, j)
                    curfeature = C(curidx, :);
                    first_window.plot_his_feature(curfeature(:));
                    title(sprintf('%d th compoenent',curidx))
                end
            end

            for i = 0:1:floor(k/n) 
                % plot raw temporal data
                % figure()
                for j = 1:n
                    curidx = n * i + j;
                    if curidx > k
                        break
                    end
                    windowidx = find(idx == curidx);
                    first_window = obj.data_windows(windowidx);
                    
                    first_window.plot_raw_feature();
                    title(sprintf('%d th compoenent',curidx));
                end
            end


            obj.pca();
            pca_coordinates = obj.pca_coordinates;
            figure()
            scatter(pca_coordinates(:,1), pca_coordinates(:,2), 50,obj.idx, 'filled')
            colorbar;
            % show original temporal feature(time series) corresponding to each feature, take the mean

        end




        %% Quantitative Analysis primarily Supervised Learning, the even more exciting part

        


    end
end
##### SOURCE END #####
--></body></html>